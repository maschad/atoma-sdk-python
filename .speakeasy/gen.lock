lockVersion: 2.0.0
id: abb58176-a92d-43ea-b418-227f4288eed7
management:
  docChecksum: c4065789f13119415ea80867f4133cd0
  docVersion: 0.1.0
  speakeasyVersion: 1.537.0
  generationVersion: 2.588.0
  releaseVersion: 0.1.1
  configChecksum: 159f3e24285516f298916681f1b981a1
  repoURL: https://github.com/atoma-network/atoma-sdk-python.git
  installationURL: https://github.com/atoma-network/atoma-sdk-python.git
features:
  python:
    additionalDependencies: 1.0.0
    constsAndDefaults: 1.0.5
    core: 5.15.0
    defaultEnabledRetries: 0.2.0
    deprecations: 3.0.2
    devContainers: 3.0.0
    enumUnions: 0.1.0
    envVarSecurityUsage: 0.3.2
    flatRequests: 1.0.1
    globalSecurity: 3.0.3
    globalSecurityCallbacks: 1.0.0
    globalSecurityFlattening: 1.0.0
    globalServerURLs: 3.1.0
    groups: 3.0.0
    methodArguments: 1.0.2
    nameOverrides: 3.0.1
    nullables: 1.0.1
    responseFormat: 1.0.1
    retries: 3.0.2
    sdkHooks: 1.0.1
    serverEvents: 1.0.7
    serverEventsSentinels: 0.1.0
    unions: 3.0.4
generatedFiles:
  - .devcontainer/README.md
  - .devcontainer/devcontainer.json
  - .devcontainer/setup.sh
  - .gitattributes
  - .python-version
  - .vscode/settings.json
  - USAGE.md
  - docs/models/assistant.md
  - docs/models/chatcompletionchoice.md
  - docs/models/chatcompletionchunk.md
  - docs/models/chatcompletionchunkchoice.md
  - docs/models/chatcompletionchunkdelta.md
  - docs/models/chatcompletionchunkdeltatoolcall.md
  - docs/models/chatcompletionchunkdeltatoolcallfunction.md
  - docs/models/chatcompletionlogprob.md
  - docs/models/chatcompletionlogprobs.md
  - docs/models/chatcompletionlogprobscontent.md
  - docs/models/chatcompletionmessage.md
  - docs/models/chatcompletionnamedfunction.md
  - docs/models/chatcompletionnamedtoolchoiceparam.md
  - docs/models/chatcompletionresponse.md
  - docs/models/chatcompletionscreatestreamresponsebody.md
  - docs/models/chatcompletiontoolfunctionparam.md
  - docs/models/chatcompletiontoolsparam.md
  - docs/models/completionchoice.md
  - docs/models/completionscreatestreamresponsebody.md
  - docs/models/completionsprompt.md
  - docs/models/completionsrequest.md
  - docs/models/completionsresponse.md
  - docs/models/completionsstreamresponse.md
  - docs/models/completiontokensdetails.md
  - docs/models/completionusage.md
  - docs/models/confidentialchatcompletionscreatestreamresponsebody.md
  - docs/models/confidentialcompletionscreatestreamresponsebody.md
  - docs/models/confidentialcomputerequest.md
  - docs/models/confidentialcomputeresponse.md
  - docs/models/confidentialcomputestreamresponse.md
  - docs/models/createchatcompletionrequest.md
  - docs/models/createchatcompletionstreamrequest.md
  - docs/models/createcompletionsstreamrequest.md
  - docs/models/createembeddingrequest.md
  - docs/models/createembeddingresponse.md
  - docs/models/createimagerequest.md
  - docs/models/createimageresponse.md
  - docs/models/embeddinginput.md
  - docs/models/embeddingobject.md
  - docs/models/embeddingusage.md
  - docs/models/healthresponse.md
  - docs/models/imagedata.md
  - docs/models/jsonschemaresponseformat.md
  - docs/models/logprobs.md
  - docs/models/messagecontent.md
  - docs/models/messagecontentpart1.md
  - docs/models/messagecontentpart2.md
  - docs/models/messagecontentpartimageurl.md
  - docs/models/messagecontentpartunion.md
  - docs/models/model.md
  - docs/models/modellist.md
  - docs/models/nodepublicaddressassignment.md
  - docs/models/nodescreatelockrequest.md
  - docs/models/nodescreatelockresponse.md
  - docs/models/nodescreaterequest.md
  - docs/models/nodescreateresponse.md
  - docs/models/prompttokensdetails.md
  - docs/models/responseformat.md
  - docs/models/responseformattype.md
  - docs/models/roleassistant.md
  - docs/models/rolesystem.md
  - docs/models/roletool.md
  - docs/models/roleuser.md
  - docs/models/security.md
  - docs/models/stopreason1.md
  - docs/models/stopreason2.md
  - docs/models/stopreasonunion.md
  - docs/models/streamoptions.md
  - docs/models/system.md
  - docs/models/tool.md
  - docs/models/toolcall.md
  - docs/models/toolcallfunction.md
  - docs/models/toolchoice.md
  - docs/models/toolchoiceliteral.md
  - docs/models/usage.md
  - docs/models/user.md
  - docs/models/utils/retryconfig.md
  - docs/sdks/atomasdk/README.md
  - docs/sdks/chat/README.md
  - docs/sdks/completions/README.md
  - docs/sdks/confidentialchat/README.md
  - docs/sdks/confidentialcompletions/README.md
  - docs/sdks/confidentialembeddings/README.md
  - docs/sdks/confidentialimages/README.md
  - docs/sdks/embeddings/README.md
  - docs/sdks/health/README.md
  - docs/sdks/images/README.md
  - docs/sdks/models/README.md
  - docs/sdks/nodes/README.md
  - poetry.toml
  - py.typed
  - pylintrc
  - pyproject.toml
  - scripts/prepare_readme.py
  - scripts/publish.sh
  - src/atoma_sdk/__init__.py
  - src/atoma_sdk/_hooks/__init__.py
  - src/atoma_sdk/_hooks/sdkhooks.py
  - src/atoma_sdk/_hooks/types.py
  - src/atoma_sdk/_version.py
  - src/atoma_sdk/basesdk.py
  - src/atoma_sdk/chat.py
  - src/atoma_sdk/completions.py
  - src/atoma_sdk/confidentialchat.py
  - src/atoma_sdk/confidentialcompletions.py
  - src/atoma_sdk/confidentialembeddings.py
  - src/atoma_sdk/confidentialimages.py
  - src/atoma_sdk/embeddings.py
  - src/atoma_sdk/health.py
  - src/atoma_sdk/httpclient.py
  - src/atoma_sdk/images.py
  - src/atoma_sdk/models/__init__.py
  - src/atoma_sdk/models/apierror.py
  - src/atoma_sdk/models/chat_completions_create_streamop.py
  - src/atoma_sdk/models/chatcompletionchoice.py
  - src/atoma_sdk/models/chatcompletionchunk.py
  - src/atoma_sdk/models/chatcompletionchunkchoice.py
  - src/atoma_sdk/models/chatcompletionchunkdelta.py
  - src/atoma_sdk/models/chatcompletionchunkdeltatoolcall.py
  - src/atoma_sdk/models/chatcompletionchunkdeltatoolcallfunction.py
  - src/atoma_sdk/models/chatcompletionlogprob.py
  - src/atoma_sdk/models/chatcompletionlogprobs.py
  - src/atoma_sdk/models/chatcompletionlogprobscontent.py
  - src/atoma_sdk/models/chatcompletionmessage.py
  - src/atoma_sdk/models/chatcompletionnamedfunction.py
  - src/atoma_sdk/models/chatcompletionnamedtoolchoiceparam.py
  - src/atoma_sdk/models/chatcompletionresponse.py
  - src/atoma_sdk/models/chatcompletiontoolfunctionparam.py
  - src/atoma_sdk/models/chatcompletiontoolsparam.py
  - src/atoma_sdk/models/completionchoice.py
  - src/atoma_sdk/models/completions_create_streamop.py
  - src/atoma_sdk/models/completionsprompt.py
  - src/atoma_sdk/models/completionsrequest.py
  - src/atoma_sdk/models/completionsresponse.py
  - src/atoma_sdk/models/completionsstreamresponse.py
  - src/atoma_sdk/models/completiontokensdetails.py
  - src/atoma_sdk/models/completionusage.py
  - src/atoma_sdk/models/confidential_chat_completions_create_streamop.py
  - src/atoma_sdk/models/confidential_completions_create_streamop.py
  - src/atoma_sdk/models/confidentialcomputerequest.py
  - src/atoma_sdk/models/confidentialcomputeresponse.py
  - src/atoma_sdk/models/confidentialcomputestreamresponse.py
  - src/atoma_sdk/models/createchatcompletionrequest.py
  - src/atoma_sdk/models/createchatcompletionstreamrequest.py
  - src/atoma_sdk/models/createcompletionsstreamrequest.py
  - src/atoma_sdk/models/createembeddingrequest.py
  - src/atoma_sdk/models/createembeddingresponse.py
  - src/atoma_sdk/models/createimagerequest.py
  - src/atoma_sdk/models/createimageresponse.py
  - src/atoma_sdk/models/embeddinginput.py
  - src/atoma_sdk/models/embeddingobject.py
  - src/atoma_sdk/models/embeddingusage.py
  - src/atoma_sdk/models/healthresponse.py
  - src/atoma_sdk/models/imagedata.py
  - src/atoma_sdk/models/jsonschemaresponseformat.py
  - src/atoma_sdk/models/logprobs.py
  - src/atoma_sdk/models/messagecontent.py
  - src/atoma_sdk/models/messagecontentpart_union.py
  - src/atoma_sdk/models/messagecontentpartimageurl.py
  - src/atoma_sdk/models/model.py
  - src/atoma_sdk/models/modellist.py
  - src/atoma_sdk/models/nodepublicaddressassignment.py
  - src/atoma_sdk/models/nodescreatelockrequest.py
  - src/atoma_sdk/models/nodescreatelockresponse.py
  - src/atoma_sdk/models/nodescreaterequest.py
  - src/atoma_sdk/models/nodescreateresponse.py
  - src/atoma_sdk/models/prompttokensdetails.py
  - src/atoma_sdk/models/responseformat.py
  - src/atoma_sdk/models/responseformattype.py
  - src/atoma_sdk/models/security.py
  - src/atoma_sdk/models/stopreason_union.py
  - src/atoma_sdk/models/streamoptions.py
  - src/atoma_sdk/models/toolcall.py
  - src/atoma_sdk/models/toolcallfunction.py
  - src/atoma_sdk/models/toolchoice.py
  - src/atoma_sdk/models/toolchoiceliteral.py
  - src/atoma_sdk/models/usage.py
  - src/atoma_sdk/models_.py
  - src/atoma_sdk/nodes.py
  - src/atoma_sdk/py.typed
  - src/atoma_sdk/sdk.py
  - src/atoma_sdk/sdkconfiguration.py
  - src/atoma_sdk/types/__init__.py
  - src/atoma_sdk/types/basemodel.py
  - src/atoma_sdk/utils/__init__.py
  - src/atoma_sdk/utils/annotations.py
  - src/atoma_sdk/utils/datetimes.py
  - src/atoma_sdk/utils/enums.py
  - src/atoma_sdk/utils/eventstreaming.py
  - src/atoma_sdk/utils/forms.py
  - src/atoma_sdk/utils/headers.py
  - src/atoma_sdk/utils/logger.py
  - src/atoma_sdk/utils/metadata.py
  - src/atoma_sdk/utils/queryparams.py
  - src/atoma_sdk/utils/requestbodies.py
  - src/atoma_sdk/utils/retries.py
  - src/atoma_sdk/utils/security.py
  - src/atoma_sdk/utils/serializers.py
  - src/atoma_sdk/utils/url.py
  - src/atoma_sdk/utils/values.py
examples:
  completions_create:
    speakeasy-default-completions-create:
      requestBody:
        application/json: {"best_of": 1, "echo": false, "frequency_penalty": 0, "logit_bias": {"1234567890": 0.5, "1234567891": -0.5}, "logprobs": 1, "max_tokens": 4096, "model": "meta-llama/Llama-3.3-70B-Instruct", "n": 1, "presence_penalty": 0, "prompt": ["<value>", "<value>"], "seed": 123, "stop": ["json([\"stop\", \"halt\"])"], "stream": false, "suffix": "json(\"\\n\")", "temperature": 0.7, "top_p": 1, "user": "user-1234"}
      responses:
        "200":
          application/json: {"choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "text": "This is a test"}], "created": "2021-01-01T00:00:00Z", "id": "cmpl-1234567890", "model": "meta-llama/Llama-3.3-70B-Instruct", "object": "text_completion", "system_fingerprint": "system-fingerprint", "usage": {"completion_tokens": 10, "completion_tokens_details": {"accepted_prediction_tokens": 10, "audio_tokens": 0, "reasoning_tokens": 10, "rejected_prediction_tokens": 0}, "prompt_tokens": 10, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 10}, "total_tokens": 20}}
  completions_create_stream:
    speakeasy-default-completions-create-stream:
      requestBody:
        application/json: {"best_of": 1, "echo": false, "frequency_penalty": 0, "logit_bias": {"1234567890": 0.5, "1234567891": -0.5}, "logprobs": 1, "max_tokens": 4096, "model": "meta-llama/Llama-3.3-70B-Instruct", "n": 1, "presence_penalty": 0, "prompt": "<value>", "seed": 123, "stop": ["json([\"stop\", \"halt\"])"], "stream": true, "suffix": "json(\"\\n\")", "temperature": 0.7, "top_p": 1, "user": "user-1234"}
  confidential_completions_create:
    speakeasy-default-confidential-completions-create:
      requestBody:
        application/json: {"ciphertext": "<value>", "client_dh_public_key": "<value>", "model_name": "<value>", "node_dh_public_key": "<value>", "nonce": "<value>", "plaintext_body_hash": "<value>", "salt": "<value>", "stack_small_id": 486589}
      responses:
        "200":
          application/json: {"ciphertext": "<value>", "nonce": "<value>", "usage": {"completion_tokens": 10, "completion_tokens_details": {"accepted_prediction_tokens": 10, "audio_tokens": 0, "reasoning_tokens": 10, "rejected_prediction_tokens": 0}, "prompt_tokens": 10, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 10}, "total_tokens": 20}}
  confidential_completions_create_stream:
    speakeasy-default-confidential-completions-create-stream:
      requestBody:
        application/json: {"ciphertext": "<value>", "client_dh_public_key": "<value>", "model_name": "<value>", "node_dh_public_key": "<value>", "nonce": "<value>", "plaintext_body_hash": "<value>", "salt": "<value>", "stack_small_id": 180107}
  chat_completions_create:
    speakeasy-default-chat-completions-create:
      requestBody:
        application/json: {"frequency_penalty": 0, "functions": [{"name": "get_current_weather", "description": "Get the current weather in a location", "parameters": {"type": "object", "properties": {"location": {"type": "string", "description": "The location to get the weather for"}}, "required": ["location"]}}], "logit_bias": {"1234567890": 0.5, "1234567891": -0.5}, "max_completion_tokens": 4096, "messages": [{"content": "You are a helpful AI assistant", "name": "AI expert", "role": "system"}, {"content": "Hello!", "name": "John Doe", "role": "user"}, {"content": "I'm here to help you with any questions you have. How can I assist you today?", "name": "AI", "role": "assistant"}], "model": "meta-llama/Llama-3.3-70B-Instruct", "n": 1, "parallel_tool_calls": true, "presence_penalty": 0, "seed": 123, "service_tier": "auto", "stop": ["json([\"stop\", \"halt\"])"], "stream": false, "temperature": 0.7, "tools": [{"function": {"description": "Get the current weather in a location", "name": "get_current_weather", "parameters": {"type": "object", "properties": {"location": {"type": "string", "description": "The location to get the weather for"}}, "required": ["location"]}}, "type": "function"}], "top_logprobs": 1, "top_p": 1, "user": "user-1234"}
      responses:
        "200":
          application/json: {"choices": [{"finish_reason": "stop", "index": 0, "message": {"name": "John Doe", "role": "user"}}], "created": 1677652288, "id": "chatcmpl-123", "model": "meta-llama/Llama-3.3-70B-Instruct", "object": "chat.completion", "service_tier": "auto", "system_fingerprint": "fp_44709d6fcb", "usage": {"completion_tokens": 12, "prompt_tokens": 9, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 10}, "total_tokens": 21}}
  chat_completions_create_stream:
    speakeasy-default-chat-completions-create-stream:
      requestBody:
        application/json: {"frequency_penalty": 0, "functions": [{"name": "get_current_weather", "description": "Get the current weather in a location", "parameters": {"type": "object", "properties": {"location": {"type": "string", "description": "The location to get the weather for"}}, "required": ["location"]}}], "logit_bias": {"1234567890": 0.5, "1234567891": -0.5}, "max_completion_tokens": 4096, "messages": [{"content": "You are a helpful AI assistant", "name": "AI expert", "role": "system"}, {"content": "Hello!", "name": "John Doe", "role": "user"}, {"content": "I'm here to help you with any questions you have. How can I assist you today?", "name": "AI", "role": "assistant"}], "model": "meta-llama/Llama-3.3-70B-Instruct", "n": 1, "parallel_tool_calls": true, "presence_penalty": 0, "seed": 123, "service_tier": "auto", "stop": ["json([\"stop\", \"halt\"])"], "stream": true, "temperature": 0.7, "tools": [{"function": {"description": "Get the current weather in a location", "name": "get_current_weather", "parameters": {"type": "object", "properties": {"location": {"type": "string", "description": "The location to get the weather for"}}, "required": ["location"]}}, "type": "function"}], "top_logprobs": 1, "top_p": 1, "user": "user-1234"}
  confidential_chat_completions_create:
    speakeasy-default-confidential-chat-completions-create:
      requestBody:
        application/json: {"ciphertext": "<value>", "client_dh_public_key": "<value>", "model_name": "<value>", "node_dh_public_key": "<value>", "nonce": "<value>", "plaintext_body_hash": "<value>", "salt": "<value>", "stack_small_id": 486589}
      responses:
        "200":
          application/json: {"ciphertext": "<value>", "nonce": "<value>", "usage": {"completion_tokens": 10, "completion_tokens_details": {"accepted_prediction_tokens": 10, "audio_tokens": 0, "reasoning_tokens": 10, "rejected_prediction_tokens": 0}, "prompt_tokens": 10, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 10}, "total_tokens": 20}}
  confidential_chat_completions_create_stream:
    speakeasy-default-confidential-chat-completions-create-stream:
      requestBody:
        application/json: {"ciphertext": "<value>", "client_dh_public_key": "<value>", "model_name": "<value>", "node_dh_public_key": "<value>", "nonce": "<value>", "plaintext_body_hash": "<value>", "salt": "<value>", "stack_small_id": 180107}
  confidential_embeddings_create:
    speakeasy-default-confidential-embeddings-create:
      requestBody:
        application/json: {"ciphertext": "<value>", "client_dh_public_key": "<value>", "model_name": "<value>", "node_dh_public_key": "<value>", "nonce": "<value>", "plaintext_body_hash": "<value>", "salt": "<value>", "stack_small_id": 486589}
      responses:
        "200":
          application/json: {"ciphertext": "<value>", "nonce": "<value>", "usage": {"completion_tokens": 10, "completion_tokens_details": {"accepted_prediction_tokens": 10, "audio_tokens": 0, "reasoning_tokens": 10, "rejected_prediction_tokens": 0}, "prompt_tokens": 10, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 10}, "total_tokens": 20}}
  confidential_image_generations_create:
    speakeasy-default-confidential-image-generations-create:
      requestBody:
        application/json: {"ciphertext": "<value>", "client_dh_public_key": "<value>", "model_name": "<value>", "node_dh_public_key": "<value>", "nonce": "<value>", "plaintext_body_hash": "<value>", "salt": "<value>", "stack_small_id": 740198}
      responses:
        "200":
          application/json: {"ciphertext": "<value>", "nonce": "<value>", "usage": {"completion_tokens": 10, "completion_tokens_details": {"accepted_prediction_tokens": 10, "audio_tokens": 0, "reasoning_tokens": 10, "rejected_prediction_tokens": 0}, "prompt_tokens": 10, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 10}, "total_tokens": 20}}
  embeddings_create:
    speakeasy-default-embeddings-create:
      requestBody:
        application/json: {"encoding_format": "float", "input": "The quick brown fox jumped over the lazy dog", "model": "intfloat/multilingual-e5-large-instruct", "user": "user-1234"}
      responses:
        "200":
          application/json: {"data": [{"embedding": ["[0.0023064255, -0.009327292]"], "index": 0, "object": "embedding"}, {"embedding": ["[0.0023064255, -0.009327292]"], "index": 0, "object": "embedding"}], "model": "intfloat/multilingual-e5-large-instruct", "object": "list", "usage": {"prompt_tokens": 8, "total_tokens": 8}}
  health:
    speakeasy-default-health:
      responses:
        "200":
          application/json: {"message": "<value>"}
  image_generations_create:
    speakeasy-default-image-generations-create:
      requestBody:
        application/json: {"model": "black-forest-labs/FLUX.1-schnell", "n": 1, "prompt": "A cute baby sea otter floating on its back", "quality": "hd", "response_format": "url", "size": "1024x1024", "style": "vivid", "user": "user-1234"}
      responses:
        "200":
          application/json: {"created": 1677649420, "data": [{"revised_prompt": "A stunning image of a baby sea otter floating on its back in crystal clear blue water, with gentle ripples surrounding it. The otter's fur appears soft and well-detailed, and its expression is peaceful and content.", "url": "https://oaidalleapiprodscus.blob.core.windows.net/private/image.png"}, {"revised_prompt": "A stunning image of a baby sea otter floating on its back in crystal clear blue water, with gentle ripples surrounding it. The otter's fur appears soft and well-detailed, and its expression is peaceful and content.", "url": "https://oaidalleapiprodscus.blob.core.windows.net/private/image.png"}]}
  models_list:
    speakeasy-default-models-list:
      responses:
        "200":
          application/json: {"data": [{"created": 640785, "id": "<id>", "object": "<value>", "owned_by": "<value>"}, {"created": 744692, "id": "<id>", "object": "<value>", "owned_by": "<value>"}, {"created": 941970, "id": "<id>", "object": "<value>", "owned_by": "<value>"}], "object": "<value>"}
  open_router_models_list:
    speakeasy-default-open-router-models-list:
      responses:
        "200":
          application/json: "<value>"
  nodes_create:
    speakeasy-default-nodes-create:
      requestBody:
        application/json: {"data": {"country": "Andorra", "node_small_id": 3665, "public_address": "<value>"}, "signature": "<value>"}
      responses:
        "200":
          application/json: {"message": "<value>"}
  nodes_create_lock:
    speakeasy-default-nodes-create-lock:
      requestBody:
        application/json: {"model": "Focus"}
      responses:
        "200":
          application/json: {"node_small_id": 248208, "public_key": "<value>", "stack_small_id": 863000}
examplesVersion: 1.0.1
generatedTests: {}
