"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from .basesdk import BaseSDK
from atoma_sdk import models, utils
from atoma_sdk._hooks import HookContext
from atoma_sdk.types import OptionalNullable, UNSET
from atoma_sdk.utils import get_security_from_env
from typing import Mapping, Optional


class ConfidentialEmbeddings(BaseSDK):
    def create(
        self,
        *,
        ciphertext: str,
        client_dh_public_key: str,
        model_name: str,
        node_dh_public_key: str,
        nonce: str,
        plaintext_body_hash: str,
        salt: str,
        stack_small_id: int,
        num_compute_units: OptionalNullable[int] = UNSET,
        stream: OptionalNullable[bool] = UNSET,
        retries: OptionalNullable[utils.RetryConfig] = UNSET,
        server_url: Optional[str] = None,
        timeout_ms: Optional[int] = None,
        http_headers: Optional[Mapping[str, str]] = None,
    ) -> models.ConfidentialComputeResponse:
        r"""Create confidential embeddings

        This endpoint follows the OpenAI API format for generating vector embeddings from input text,
        but with confidential processing (through AEAD encryption and TEE hardware).
        The handler receives pre-processed metadata from middleware and forwards the request to
        the selected node.

        ## Returns
        * `Ok(Response)` - The embeddings response from the processing node
        * `Err(AtomaProxyError)` - An error status code if any step fails

        ## Errors
        * `INTERNAL_SERVER_ERROR` - Processing or node communication failures

        :param ciphertext: The encrypted payload that needs to be processed (base64 encoded)
        :param client_dh_public_key: Client's public key for Diffie-Hellman key exchange (base64 encoded)
        :param model_name: Model name
        :param node_dh_public_key: Node's public key for Diffie-Hellman key exchange (base64 encoded)
        :param nonce: Cryptographic nonce used for encryption (base64 encoded)
        :param plaintext_body_hash: Hash of the original plaintext body for integrity verification (base64 encoded)
        :param salt: Salt value used in key derivation (base64 encoded)
        :param stack_small_id: Unique identifier for the small stack being used
        :param num_compute_units: Number of compute units to be used for the request, for image generations, as this value is known in advance (the number of pixels to generate)
        :param stream: Indicates whether this is a streaming request
        :param retries: Override the default retry configuration for this method
        :param server_url: Override the default server URL for this method
        :param timeout_ms: Override the default request timeout configuration for this method in milliseconds
        :param http_headers: Additional headers to set or replace on requests.
        """
        base_url = None
        url_variables = None
        if timeout_ms is None:
            timeout_ms = self.sdk_configuration.timeout_ms

        if server_url is not None:
            base_url = server_url
        else:
            base_url = self._get_url(base_url, url_variables)

        request = models.ConfidentialComputeRequest(
            ciphertext=ciphertext,
            client_dh_public_key=client_dh_public_key,
            model_name=model_name,
            node_dh_public_key=node_dh_public_key,
            nonce=nonce,
            num_compute_units=num_compute_units,
            plaintext_body_hash=plaintext_body_hash,
            salt=salt,
            stack_small_id=stack_small_id,
            stream=stream,
        )

        req = self._build_request(
            method="POST",
            path="/v1/confidential/embeddings",
            base_url=base_url,
            url_variables=url_variables,
            request=request,
            request_body_required=True,
            request_has_path_params=False,
            request_has_query_params=True,
            user_agent_header="user-agent",
            accept_header_value="application/json",
            http_headers=http_headers,
            security=self.sdk_configuration.security,
            get_serialized_body=lambda: utils.serialize_request_body(
                request, False, False, "json", models.ConfidentialComputeRequest
            ),
            timeout_ms=timeout_ms,
        )

        if retries == UNSET:
            if self.sdk_configuration.retry_config is not UNSET:
                retries = self.sdk_configuration.retry_config

        retry_config = None
        if isinstance(retries, utils.RetryConfig):
            retry_config = (retries, ["429", "500", "502", "503", "504"])

        http_res = self.do_request(
            hook_ctx=HookContext(
                base_url=base_url or "",
                operation_id="confidential_embeddings_create",
                oauth2_scopes=[],
                security_source=get_security_from_env(
                    self.sdk_configuration.security, models.Security
                ),
            ),
            request=req,
            error_status_codes=["400", "401", "4XX", "500", "5XX"],
            retry_config=retry_config,
        )

        if utils.match_response(http_res, "200", "application/json"):
            return utils.unmarshal_json(
                http_res.text, models.ConfidentialComputeResponse
            )
        if utils.match_response(http_res, ["400", "401", "4XX"], "*"):
            http_res_text = utils.stream_to_text(http_res)
            raise models.APIError(
                "API error occurred", http_res.status_code, http_res_text, http_res
            )
        if utils.match_response(http_res, ["500", "5XX"], "*"):
            http_res_text = utils.stream_to_text(http_res)
            raise models.APIError(
                "API error occurred", http_res.status_code, http_res_text, http_res
            )

        content_type = http_res.headers.get("Content-Type")
        http_res_text = utils.stream_to_text(http_res)
        raise models.APIError(
            f"Unexpected response received (code: {http_res.status_code}, type: {content_type})",
            http_res.status_code,
            http_res_text,
            http_res,
        )

    async def create_async(
        self,
        *,
        ciphertext: str,
        client_dh_public_key: str,
        model_name: str,
        node_dh_public_key: str,
        nonce: str,
        plaintext_body_hash: str,
        salt: str,
        stack_small_id: int,
        num_compute_units: OptionalNullable[int] = UNSET,
        stream: OptionalNullable[bool] = UNSET,
        retries: OptionalNullable[utils.RetryConfig] = UNSET,
        server_url: Optional[str] = None,
        timeout_ms: Optional[int] = None,
        http_headers: Optional[Mapping[str, str]] = None,
    ) -> models.ConfidentialComputeResponse:
        r"""Create confidential embeddings

        This endpoint follows the OpenAI API format for generating vector embeddings from input text,
        but with confidential processing (through AEAD encryption and TEE hardware).
        The handler receives pre-processed metadata from middleware and forwards the request to
        the selected node.

        ## Returns
        * `Ok(Response)` - The embeddings response from the processing node
        * `Err(AtomaProxyError)` - An error status code if any step fails

        ## Errors
        * `INTERNAL_SERVER_ERROR` - Processing or node communication failures

        :param ciphertext: The encrypted payload that needs to be processed (base64 encoded)
        :param client_dh_public_key: Client's public key for Diffie-Hellman key exchange (base64 encoded)
        :param model_name: Model name
        :param node_dh_public_key: Node's public key for Diffie-Hellman key exchange (base64 encoded)
        :param nonce: Cryptographic nonce used for encryption (base64 encoded)
        :param plaintext_body_hash: Hash of the original plaintext body for integrity verification (base64 encoded)
        :param salt: Salt value used in key derivation (base64 encoded)
        :param stack_small_id: Unique identifier for the small stack being used
        :param num_compute_units: Number of compute units to be used for the request, for image generations, as this value is known in advance (the number of pixels to generate)
        :param stream: Indicates whether this is a streaming request
        :param retries: Override the default retry configuration for this method
        :param server_url: Override the default server URL for this method
        :param timeout_ms: Override the default request timeout configuration for this method in milliseconds
        :param http_headers: Additional headers to set or replace on requests.
        """
        base_url = None
        url_variables = None
        if timeout_ms is None:
            timeout_ms = self.sdk_configuration.timeout_ms

        if server_url is not None:
            base_url = server_url
        else:
            base_url = self._get_url(base_url, url_variables)

        request = models.ConfidentialComputeRequest(
            ciphertext=ciphertext,
            client_dh_public_key=client_dh_public_key,
            model_name=model_name,
            node_dh_public_key=node_dh_public_key,
            nonce=nonce,
            num_compute_units=num_compute_units,
            plaintext_body_hash=plaintext_body_hash,
            salt=salt,
            stack_small_id=stack_small_id,
            stream=stream,
        )

        req = self._build_request_async(
            method="POST",
            path="/v1/confidential/embeddings",
            base_url=base_url,
            url_variables=url_variables,
            request=request,
            request_body_required=True,
            request_has_path_params=False,
            request_has_query_params=True,
            user_agent_header="user-agent",
            accept_header_value="application/json",
            http_headers=http_headers,
            security=self.sdk_configuration.security,
            get_serialized_body=lambda: utils.serialize_request_body(
                request, False, False, "json", models.ConfidentialComputeRequest
            ),
            timeout_ms=timeout_ms,
        )

        if retries == UNSET:
            if self.sdk_configuration.retry_config is not UNSET:
                retries = self.sdk_configuration.retry_config

        retry_config = None
        if isinstance(retries, utils.RetryConfig):
            retry_config = (retries, ["429", "500", "502", "503", "504"])

        http_res = await self.do_request_async(
            hook_ctx=HookContext(
                base_url=base_url or "",
                operation_id="confidential_embeddings_create",
                oauth2_scopes=[],
                security_source=get_security_from_env(
                    self.sdk_configuration.security, models.Security
                ),
            ),
            request=req,
            error_status_codes=["400", "401", "4XX", "500", "5XX"],
            retry_config=retry_config,
        )

        if utils.match_response(http_res, "200", "application/json"):
            return utils.unmarshal_json(
                http_res.text, models.ConfidentialComputeResponse
            )
        if utils.match_response(http_res, ["400", "401", "4XX"], "*"):
            http_res_text = await utils.stream_to_text_async(http_res)
            raise models.APIError(
                "API error occurred", http_res.status_code, http_res_text, http_res
            )
        if utils.match_response(http_res, ["500", "5XX"], "*"):
            http_res_text = await utils.stream_to_text_async(http_res)
            raise models.APIError(
                "API error occurred", http_res.status_code, http_res_text, http_res
            )

        content_type = http_res.headers.get("Content-Type")
        http_res_text = await utils.stream_to_text_async(http_res)
        raise models.APIError(
            f"Unexpected response received (code: {http_res.status_code}, type: {content_type})",
            http_res.status_code,
            http_res_text,
            http_res,
        )
